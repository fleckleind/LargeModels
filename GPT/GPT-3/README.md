# GPT-3
[Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165)

GPT-3: an autoregressive language model with 175 billion parameters 10x more than any previous non-sparse language model, and test its performance in the few-shot setting, without any gradient updates or fine-tuning.
